import json
import os
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import requests
from bs4 import BeautifulSoup

# -------------------- Ïù∏Ï¶ù --------------------
def get_google_client():
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_name(
        os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON"), scope
    )
    return gspread.authorize(creds)

# -------------------- ÏãúÌä∏ ÌååÏã± --------------------
def parse_sheet():
    try:
        sheet_id = os.getenv("GOOGLE_SHEET_ID")
        client = get_google_client()
        sheet = client.open_by_key(sheet_id).sheet1
        data = sheet.get_all_values()

        if not data or len(data) < 2:
            return "ÏãúÌä∏Ïóê Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§."

        headers = [h.strip().lower() for h in data[0]]
        rows = data[1:]

        text_rows = []
        for row in rows:
            if all(not cell.strip() for cell in row):
                continue  # ÏôÑÏ†ÑÌûà Îπà ÌñâÏùÄ Î¨¥Ïãú

            entry = []
            for h, v in zip(headers, row):
                v = v.strip()
                if not v or h in ['ÎπÑÍ≥†', 'Ï∞∏Í≥†']:  # Î¨¥ÏùòÎØ∏Ìïú Ïó¥ Ï†úÍ±∞
                    continue
                entry.append(f"{h}: {v}")

            if entry:
                text_rows.append(", ".join(entry))

        return "\n".join(text_rows)

    except Exception as e:
        return f"ÏãúÌä∏ ÌååÏã± Ïã§Ìå®: {e}"

# -------------------- Î¨∏ÏÑú ÌååÏã± --------------------
def parse_doc():
    try:
        doc_url = os.getenv("GOOGLE_DOC_URL")
        response = requests.get(doc_url)

        if not response.ok:
            return f"Î¨∏ÏÑú Ï†ëÍ∑º Ïã§Ìå®: {response.status_code}"

        soup = BeautifulSoup(response.content, "html.parser")
        body = soup.find('body')
        if not body:
            return "Î¨∏ÏÑú Íµ¨Ï°∞ Î∂ÑÏÑù Ïã§Ìå®: body ÌÉúÍ∑∏ ÏóÜÏùå"

        lines = []
        for tag in body.find_all(['h1', 'h2', 'h3', 'p', 'li']):
            text = tag.get_text().strip()

            # ÌïÑÌÑ∞ÎßÅ Í∏∞Ï§Ä
            if not text:
                continue
            if any(text.lower().startswith(prefix) for prefix in ["Ï∞∏Í≥†", "ÎπÑÍ≥†", "Ï∂îÍ∞Ä"]):
                continue

            # ÌÉúÍ∑∏ Íµ¨Ï°∞ Í∞ïÏ°∞
            if tag.name in ['h1', 'h2', 'h3']:
                lines.append(f"\nüìå {text}\n")
            elif tag.name == 'li':
                if len(text) < 3:  # ÎÑàÎ¨¥ ÏßßÏùÄ Î¶¨Ïä§Ìä∏ Ìï≠Î™© Ï†úÍ±∞
                    continue
                lines.append(f"- {text}")
            elif tag.name == 'p':
                if len(text.split()) < 3:  # ÏùòÎØ∏ ÏóÜÎäî Î¨∏Ïû• Ï†úÍ±∞
                    continue
                lines.append(text)

        # Ï§ëÎ≥µ Ï†úÍ±∞ + Ï†ïÏ†ú Ï∂úÎ†•
        unique_lines = list(dict.fromkeys(lines))  # ÏàúÏÑú Î≥¥Ï°¥ + Ï§ëÎ≥µ Ï†úÍ±∞
        return "\n".join(unique_lines).strip()

    except Exception as e:
        return f"Î¨∏ÏÑú ÌååÏã± Ïã§Ìå®: {e}"
    
# parser.py

def get_manual_text():
    """refiner.pyÏôÄ Í≥µÏú†Ìï† Ïàò ÏûàÎèÑÎ°ù ÏÉÅÎã¥ Îß§Îâ¥Ïñº Î∂àÎü¨Ïò§Í∏∞"""
    manual_path = os.getenv("MANUAL_PATH", "data/manual.txt")
    if not os.path.exists(manual_path):
        return "ÏÉÅÎã¥ Îß§Îâ¥ÏñºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."
    with open(manual_path, "r", encoding="utf-8") as f:
        return f.read()
